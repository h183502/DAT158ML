{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alexander S. Lundervold, November 6th, 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Under construction***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook and the next is meant to give you a taste of neural networks and deep learning. This is a very large field and the taste will be small. The goal is to perhaps satisfy some of your curiosity (\"What is deep learning? How do you *do* deep learning\") and point you towards ways to learn more about the topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll see how to construct a basic deep neural network in PyTorch, and how to train it to perform a task. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better understanding of what neural networks are and how they work, I recommend watching the following two videos. They give a nice high-level understanding. To learn more about the details, see the references listed on Canvas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/aircAruvnKk\" \n",
       "frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen>\n",
       "</iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/aircAruvnKk\" \n",
    "frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen>\n",
    "</iframe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IHZwWFHWa-w\" \n",
       "frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen>\n",
       "</iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IHZwWFHWa-w\" \n",
    "frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen>\n",
    "</iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we'll construct what's called a *convolutional neural network*, the best kind of neural network for images (and more, see the lecture slides for details). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=60% autoplay loop> <source src=\"assets/CNN-viz-otavio-good.mp4\"> </video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<video width=60% autoplay loop> <source src=\"assets/CNN-viz-otavio-good.mp4\"> </video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't cover how CNNs work in any detail, but the lecture will give some motivation for why one would want to do CNNs rather than standard fully-connected neural networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more about how CNNs work, I recommend watching the video below. It gives a nice high-level introduction to convolutional neural networks. For more in-depth understanding consult the references listed on Canvas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/FmpDIaiMIeA\" \n",
       "frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen>\n",
       "</iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/FmpDIaiMIeA\" \n",
    "frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen>\n",
    "</iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# To automatically reload modules defined in external files.\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# To display plots directly in the notebook:\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import sklearn\n",
    "import shutil\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# To make the notebook reproducible\n",
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In addition to our standard framework imported above, we'll need both torch and torchvision:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "*If you have problems importing these, see https://github.com/alu042/DAT158ML for troubleshooting tips, or ask Alexander or a TA for assistance.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} -c pytorch pytorch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use a famous benchmark data set, widely studied by the computer vision community: <a href=\"https://www.cs.toronto.edu/~kriz/cifar.html\">Cifar-10</a>. \n",
    "\n",
    "It consists of 60.000 32x32 color images from 10 different classes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/cifar10.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to create a system that can recognize what's in each image. That is, an **image classifier**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "num_classes = len(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 50.000 training images and 10.000 test images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data into PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch (and other deep learning frameworks) operate on what's called **tensors**, which are essentially multidimensional arrays that can be placed on GPUs for accellerated computing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To process the Cifar-10 images we need to convert them to tensors:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`utils.py` contains the code used to download the images, normalize them (to improve neural network performance), convert them into tensors, and create data loaders for PyTorch. Take a look if you're curious. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from utils import get_cifar10, plot_cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainloader, testloader = get_cifar10(batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot some images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are a few images and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['frog', 'bird', 'horse', 'plane']\n"
     ]
    }
   ],
   "source": [
    "plot_cifar10()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple neural networks (in PyTorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we discussed in the lecture, there are two stages to training a neural network: a forward pass to get values for all the nodes between the input and output, and a backward pass where backpropagation (automatic differentiation and dynamic programming) and gradient descent is used to tweak all the weights in the network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make gradient descent work, we need to be able to take the derivative of each component in the network (these derivatives are computed during backpropagation). \n",
    "\n",
    "For details about these procedures, see http://cs231n.github.io/optimization-2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily PyTorch can take care of the differentiation for us (that is, the backward pass) if we create a network inheriting from `nn.Module`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A fully-connected neural net in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a simple one hidden layer neural network in PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 32*32*3 # The Cifar-10 images are 32x32 with three color channels\n",
    "hidden_size = 84 # We can choose this number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        \n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # A hidden layer\n",
    "        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        \n",
    "        # An output layer\n",
    "        self.fc2 = torch.nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    # We need to define what we want to happen in the forward phase (the backward phase is automatic)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Make the 32x32x3 image into a 32*32*3 = 3072 vector\n",
    "        x = x.view(x.size(0), -1) \n",
    "        \n",
    "        # Feed the input vector through the hidden layer and an activation function\n",
    "        x = torch.tanh(self.fc1(x)) \n",
    "        \n",
    "        # Output num_classes of numbers.\n",
    "        # We'll train the network to output a high number for the correct class\n",
    "        x = self.fc2(x) \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(input_size = input_size, hidden_size = hidden_size, num_classes = num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=3072, out_features=84, bias=True)\n",
       "  (fc2): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember the steps:\n",
    "1. Define a neural network (DONE)\n",
    "2. Collect a batch of training data (we'll use our trainloader)\n",
    "3. Send these through the network to get its predictions\n",
    "4. Measure the discrepancy between the true labels and the predictions using a loss function\n",
    "5. Update all the weights using backpropagation (to calculate the gradients) and gradient descent (to update the weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the network on a single batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, lets take a look at a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the next batch\n",
    "i, data = next(enumerate(trainloader, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now collected the first batch of 4 images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images), len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels of the first four are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 9, 6, 8])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...which means that the images are of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['car', 'truck', 'frog', 'ship']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[classes[label] for label in labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images are torch tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 32, 32])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four images (batch size), 3 color channels, images of size 32x32. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feeding the batch to the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=3072, out_features=84, bias=True)\n",
       "  (fc2): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the output of the network from these images is simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, we got four vectors of length 10. Our goal is to make the element in each vector that corresponds to the correct label for the images in the batch as large as possible, while the rest are small. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we haven't trained our network at all yet, we can't expect it to produce any good predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 1, 4, 4])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 9, 6, 8])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chances are none of the predictions are correct. This is because we've initialized the network with random weights. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To measure the discrepancy between the output and the actual labels, we'll use our good friend, **cross entropy loss**. \n",
    "\n",
    "Have a look back to Part 2 to remind yourself about cross entropy. The lecture will also give you a recap of the function (when relating neural networks to softmax regression). For another quick explanation, have a look at https://www.youtube.com/watch?v=ErfnhcEV1O8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the loss for our current batch: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(outputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2377, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `backward` method PyTorch can calculate how much each weight in the network contributed to the loss by calculating the gradient of the loss with respect to each of them (using a technique called automatic differentation, which is related to the chain rule you know from MAT108):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can update all the weights using stochastic gradient descent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take one step with the optimizer to modify each weight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network has now been trained *a tiny bit* (it has learned from the first four images). \n",
    "\n",
    "Let's see if that helped:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 9, 6, 8])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 9, 6, 8])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network improved (on these four images on which it trained..). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Your turn!** Feed the next batch to the network and check how it performs on those. Not well..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going through the training data, batch by batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea now is to repeat this batch by batch, until we've been through the entire training data set multiple times. The idea is that gradient descent will then be able to find good settings for all the weights, and we can use those when new data is fed through the network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first create a simple function for checking the accuracy of the network on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(net, dataloader=testloader):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        # Feed all the test data through the net and count the number of correct predictions:\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum()\n",
    "        \n",
    "        accuracy = correct.numpy() / total\n",
    "            \n",
    "        print('The accuracy of the network on the 10.000 test images is: %d %%' % (100 * accuracy))\n",
    "        \n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our current accuracy after training on a single batch is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the network on the 10.000 test images is: 12 %\n"
     ]
    }
   ],
   "source": [
    "_ = check_accuracy(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the network is essentially untrained this is as expected (randomly guessing among the 10 classes gives an accuracy of 10%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the entire procedure for feeding batches through the network. You can CTRL+ENTER this cell to run it multiple times. You'll see the accuracy improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss: 2.673748731613159\n",
      "The accuracy of the network on the 10.000 test images is: 13 %\n"
     ]
    }
   ],
   "source": [
    "# Get next batch\n",
    "i, data = next(enumerate(trainloader, 0))\n",
    "images, labels = data\n",
    "# A technicality: we have to zero out the gradients each time, \n",
    "# otherwise they'll accumulate\n",
    "optimizer.zero_grad()\n",
    "# Collect the outputs\n",
    "outputs = net(images)\n",
    "# Compute the loss\n",
    "loss = criterion(outputs, labels)\n",
    "print(f'Current loss: {loss}')\n",
    "# Compute the gradients of the loss with respect to all the weights\n",
    "loss.backward()\n",
    "# Update the weights using gradient descent\n",
    "optimizer.step()\n",
    "# Compute the current accuracy\n",
    "_ = check_accuracy(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Question:** How many times do you have to run the above cell to go through the entire training data set once? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a loop!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll go through the entire training set 1 time. Feel free to increase this (but it'll take quite some time as we're running on the CPU, not the GPU [for now])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the network on the 10.000 test images is: 13 %\n",
      "[1,  1000] loss: 1.954\n",
      "The accuracy of the network on the 10.000 test images is: 35 %\n",
      "----------------------------------------\n",
      "[1,  2000] loss: 1.856\n",
      "The accuracy of the network on the 10.000 test images is: 36 %\n",
      "----------------------------------------\n",
      "[1,  3000] loss: 1.818\n",
      "The accuracy of the network on the 10.000 test images is: 36 %\n",
      "----------------------------------------\n",
      "[1,  4000] loss: 1.841\n",
      "The accuracy of the network on the 10.000 test images is: 37 %\n",
      "----------------------------------------\n",
      "[1,  5000] loss: 1.794\n",
      "The accuracy of the network on the 10.000 test images is: 36 %\n",
      "----------------------------------------\n",
      "[1,  6000] loss: 1.796\n",
      "The accuracy of the network on the 10.000 test images is: 37 %\n",
      "----------------------------------------\n",
      "[1,  7000] loss: 1.788\n",
      "The accuracy of the network on the 10.000 test images is: 36 %\n",
      "----------------------------------------\n",
      "[1,  8000] loss: 1.785\n",
      "The accuracy of the network on the 10.000 test images is: 37 %\n",
      "----------------------------------------\n",
      "[1,  9000] loss: 1.795\n",
      "The accuracy of the network on the 10.000 test images is: 38 %\n",
      "----------------------------------------\n",
      "[1, 10000] loss: 1.756\n",
      "The accuracy of the network on the 10.000 test images is: 38 %\n",
      "----------------------------------------\n",
      "[1, 11000] loss: 1.763\n",
      "The accuracy of the network on the 10.000 test images is: 39 %\n",
      "----------------------------------------\n",
      "[1, 12000] loss: 1.760\n",
      "The accuracy of the network on the 10.000 test images is: 38 %\n",
      "----------------------------------------\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "# We record the accuracies during training for later analysis\n",
    "accuracies = [check_accuracy(net), ]\n",
    "\n",
    "for epoch in range(num_epochs): \n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.data\n",
    "        if i % 1000 == 999:    # print every 1000nd batch         \n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 1000))\n",
    "            \n",
    "            acc = check_accuracy(net)\n",
    "            \n",
    "            print(\"-\"*40)\n",
    "            accuracies.append(acc)\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Training complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the accuracy changes during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.ylim([0.1, 0.6])\n",
    "plt.plot(accuracies, 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we quickly reach what seems to be a plateau in accuracy. We need something else to go beyond 40%..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**That's it**, basically! Now you know the basics of training neural networks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, our above neural network is not particularly powerful. We can do much, much better..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Your turn!** Try adding a second hidden layer to the network. How does it influence performance? Try experimenting with the sizes of the hidden layers. Are you able to obtain a better result than above?\n",
    "\n",
    "> Note: if you remove the \"check_accuracy\" call in the training loop it'll speed up the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *More content will be added*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A **convolutional neural network** architecture\n",
    "- Another example based on a **a different data set**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next notebook:** The state-of-the-art in deep learning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DAT158",
   "language": "python",
   "name": "dat158"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
